---
phase: 04-vmap-batching-benchmarks
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - cogrid/tests/test_vmap_correctness.py
autonomous: true

must_haves:
  truths:
    - "jax.vmap(env.jax_reset)(keys) produces correctly shaped batched output at 1024 environments"
    - "jax.vmap(env.jax_step)(batched_state, batched_actions) executes without error at 1024 environments"
    - "Single-env reset output matches the corresponding slice of the batched reset output"
    - "Single-env step output matches the corresponding slice of the batched step output after multiple steps with varied actions"
    - "Batched output shapes have leading batch dimension (1024, ...)"
  artifacts:
    - path: "cogrid/tests/test_vmap_correctness.py"
      provides: "vmap correctness tests covering reset, step, parity, and shape validation at 1024 envs"
      contains: "test_vmap_reset_shapes"
  key_links:
    - from: "cogrid/tests/test_vmap_correctness.py"
      to: "cogrid/cogrid_env.py"
      via: "env.jax_step and env.jax_reset property access"
      pattern: "env\\.jax_(step|reset)"
---

<objective>
Write a pytest test module that verifies jax.vmap correctness over env.jax_step and env.jax_reset at 1024 parallel environments, with single-env vs batched parity verification.

Purpose: Satisfies Phase 4 Success Criteria 1 (vmap executes correctly at 1024 envs with correct shapes) and 2 (each environment in the batch produces identical results to running it individually).

Output: cogrid/tests/test_vmap_correctness.py with passing tests
</objective>

<execution_context>
@/Users/chasemcd/.claude/get-shit-done/workflows/execute-plan.md
@/Users/chasemcd/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-vmap-batching-benchmarks/04-RESEARCH.md

# Test patterns to follow:
@cogrid/tests/test_cross_backend_parity.py

# Key source interfaces:
@cogrid/cogrid_env.py  (env.jax_step, env.jax_reset properties)
@cogrid/backend/env_state.py  (EnvState dataclass with static meta fields)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create vmap correctness test suite at 1024 environments</name>
  <files>cogrid/tests/test_vmap_correctness.py</files>
  <action>
Create cogrid/tests/test_vmap_correctness.py with the following tests. Follow the pattern from test_cross_backend_parity.py for env creation and backend isolation.

All tests must `pytest.importorskip("jax")` at the start to skip if JAX is not installed.

**Setup helper:**
A `_create_jax_env(registry_id, seed)` function that:
1. Calls `_reset_backend_for_testing()` from `cogrid.backend._dispatch`
2. Imports `cogrid.envs` (trigger registration)
3. Creates env via `registry.make(registry_id, backend="jax")`
4. Calls `env.reset(seed=seed)`
5. Returns env

Use the same LAYOUTS list from test_cross_backend_parity.py:
- "Overcooked-CrampedRoom-V0"
- "Overcooked-AsymmetricAdvantages-V0"
- "Overcooked-CoordinationRing-V0"

Constants: `BATCH_SIZE = 1024`, `N_PARITY_STEPS = 5`, `N_SAMPLE_INDICES = 8` (indices to spot-check for parity).

**Test 1: test_vmap_reset_shapes (parametrize over LAYOUTS)**
- Create JAX env, get `reset_fn = env.jax_reset`
- Create batch of 1024 PRNG keys: `keys = jax.random.split(jax.random.key(0), BATCH_SIZE)`
- Call `jax.vmap(reset_fn)(keys)` -> `(batched_state, batched_obs)`
- Assert batched_obs shape is `(BATCH_SIZE, n_agents, obs_dim)` where `n_agents = env.config["num_agents"]` and `obs_dim` is derived from a single-env reset call
- Assert batched_state.agent_pos shape is `(BATCH_SIZE, n_agents, 2)`
- Assert batched_state.wall_map has leading dim BATCH_SIZE
- Assert all batched observation values are finite (no NaN/inf)
- Assert n_agents meta field is NOT batched: `batched_state.n_agents == n_agents` (scalar, not array)

**Test 2: test_vmap_step_shapes (parametrize over LAYOUTS)**
- Create JAX env, get `reset_fn`, `step_fn = env.jax_step`
- vmap reset to get batched_state
- Create batched_actions: `jnp.zeros((BATCH_SIZE, n_agents), dtype=jnp.int32)`
- Call `jax.vmap(step_fn)(batched_state, batched_actions)` -> `(new_state, obs, rew, done, infos)`
- Assert obs shape is `(BATCH_SIZE, n_agents, obs_dim)`
- Assert rew shape is `(BATCH_SIZE, n_agents)`
- Assert done shape is `(BATCH_SIZE,)`
- Assert infos is `{}` (empty dict)
- Assert new_state.agent_pos shape is `(BATCH_SIZE, n_agents, 2)`

**Test 3: test_vmap_reset_parity (parametrize over LAYOUTS)**
Single-env vs batched parity for reset. This is a critical correctness test.
- Create JAX env, get `reset_fn = env.jax_reset`
- Create keys = `jax.random.split(jax.random.key(0), BATCH_SIZE)`
- `batched_state, batched_obs = jax.vmap(reset_fn)(keys)`
- Pick `N_SAMPLE_INDICES` sample indices: `[0, 1, 2, 3, BATCH_SIZE//2, BATCH_SIZE-3, BATCH_SIZE-2, BATCH_SIZE-1]`
- For each sample index `i`:
  - `single_state, single_obs = reset_fn(keys[i])`
  - `np.testing.assert_array_equal(np.array(single_obs), np.array(batched_obs[i]))`
  - Compare all dynamic state fields (agent_pos, agent_dir, agent_inv, wall_map, object_type_map, object_state_map, pot_contents, pot_timer, pot_positions, rng_key, time)

**Test 4: test_vmap_step_parity (parametrize over LAYOUTS)**
Single-env vs batched parity for step with varied actions over multiple steps. The most critical test.
- Create JAX env, get `reset_fn`, `step_fn`
- `keys = jax.random.split(jax.random.key(0), BATCH_SIZE)`
- `batched_state, _ = jax.vmap(reset_fn)(keys)`
- Use `np.random.default_rng(123)` to generate `N_PARITY_STEPS` batches of random actions `(BATCH_SIZE, n_agents)` with values in `[0, 7)`. Convert each to `jnp.int32`. Store all actions in a list.
- Step through all `N_PARITY_STEPS` steps with vmapped step
- Pick `N_SAMPLE_INDICES` sample indices (same as test 3)
- For each sample index `i`:
  - Run single-env reset with `reset_fn(keys[i])`
  - Run single-env step through the same `N_PARITY_STEPS` steps using `actions_list[step][i]` for that env's actions
  - After all steps, compare final obs: `np.testing.assert_array_equal(np.array(single_obs), np.array(batched_obs[i]))`
  - Compare final rewards: `np.testing.assert_allclose(np.array(single_rew), np.array(batched_rew[i]), atol=1e-7)`
  - Compare final done: `np.testing.assert_array_equal(np.array(single_done), np.array(batched_done[i]))`
  - Compare all dynamic state fields of final state

**Test 5: test_vmap_jit_composition**
Verify that `jax.jit(jax.vmap(fn))` works (the optimal pattern for performance).
- Create JAX env on CrampedRoom
- `vmapped_reset = jax.jit(jax.vmap(env.jax_reset))`
- `vmapped_step = jax.jit(jax.vmap(env.jax_step))`
- Run reset + 3 steps. Assert no errors and outputs have correct batch shapes.
- This tests the jit(vmap(...)) composition recommended in the research as the optimal pattern.

**Important implementation notes:**
- Use `np.testing.assert_array_equal` for integer arrays and `np.testing.assert_allclose(atol=1e-7)` for float arrays
- Always convert JAX arrays to numpy via `np.array(...)` before assertions (matching existing test patterns)
- For state field comparison, iterate over a list of dynamic field names and use `getattr(state, field_name)` to extract values
- The `rng_key` field comparison uses `jax.random.key_data()` to extract the underlying integer data before comparing (JAX key types are opaque)
- Use descriptive `err_msg` arguments on all assertions for clear failure messages
  </action>
  <verify>
Run `python -m pytest cogrid/tests/test_vmap_correctness.py -v` from the project root. All tests must pass. Expected: 13 tests (3 layouts x 4 parametrized tests + 1 non-parametrized = 13).
  </verify>
  <done>
All 5 test functions pass on all 3 layouts. vmap reset and step produce correct shapes at 1024 envs. Single-env outputs match corresponding batched slices for both reset and step (with varied actions over 5 steps). jit(vmap(...)) composition works without error.
  </done>
</task>

</tasks>

<verification>
```bash
# Run the full vmap correctness test suite
python -m pytest cogrid/tests/test_vmap_correctness.py -v

# Verify all tests pass (no failures, no errors, no skips unless JAX not installed)
```
</verification>

<success_criteria>
1. All vmap correctness tests pass across all 3 Overcooked layouts
2. Batched outputs at 1024 environments have correct leading batch dimension
3. Single-env outputs match corresponding batched slices (exact for ints, allclose for floats)
4. jit(vmap(fn)) composition executes without error
</success_criteria>

<output>
After completion, create `.planning/phases/04-vmap-batching-benchmarks/04-01-SUMMARY.md`
</output>
